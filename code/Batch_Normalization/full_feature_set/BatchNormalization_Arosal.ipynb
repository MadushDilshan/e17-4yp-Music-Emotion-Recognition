{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, f1_score, accuracy_score, precision_score, recall_score\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the directory containing the feature files\n",
        "directory_path = '/content/drive/MyDrive/FYP_dataset/features'\n",
        "\n",
        "# Get a list of all feature file paths in the directory\n",
        "feature_files = glob.glob(directory_path + '/*.csv')\n",
        "\n",
        "# Define lists to store the feature and target data\n",
        "X = []\n",
        "y_a = []\n",
        "y_v = []\n",
        "\n",
        "# Iterate over each feature file\n",
        "for file in feature_files:\n",
        "    # Read the feature file into a DataFrame\n",
        "    df = pd.read_csv(file)\n",
        "\n",
        "    # Extract the features and target variables\n",
        "    features = df.drop(['Arousal_Value', 'Valence_Value', 'frameTime'], axis=1).values\n",
        "    arousal = df['Arousal_Value'].values\n",
        "    valence = df['Valence_Value'].values\n",
        "\n",
        "    # Append the data to the lists\n",
        "    X.append(features)\n",
        "    y_a.append(arousal)\n",
        "    y_v.append(valence)\n",
        "\n",
        "# Concatenate the feature and target arrays\n",
        "X = np.concatenate(X)\n",
        "y_a = np.concatenate(y_a)\n",
        "y_v = np.concatenate(y_v)\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Reshape the input data for LSTM\n",
        "X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "\n",
        "# Initialize lists to store evaluation results\n",
        "mse_a = []\n",
        "mae_a = []\n",
        "rmse_a = []\n",
        "r2_a = []\n",
        "f1_a = []\n",
        "accuracy_a = []\n",
        "precision_a = []\n",
        "recall_a = []\n",
        "\n",
        "# Perform tenfold cross-validation\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "for train_index, test_index in kf.split(X_reshaped):\n",
        "    X_train, X_val = X_reshaped[train_index], X_reshaped[test_index]\n",
        "    y_a_train, y_a_val = y_a[train_index], y_a[test_index]\n",
        "\n",
        "    # Split the validation set further into val and test sets\n",
        "    val_size = len(X_val) // 2\n",
        "    X_val, X_test = X_val[:val_size], X_val[val_size:]\n",
        "    y_a_val, y_a_test = y_a_val[:val_size], y_a_val[val_size:]\n",
        "\n",
        "    # Build the BiLSTM model for Arousal\n",
        "    model_a = Sequential()\n",
        "    model_a.add(Bidirectional(CuDNNLSTM(64, return_sequences=True), input_shape=(X_train.shape[1], 1)))\n",
        "    model_a.add(Flatten())\n",
        "\n",
        "    # Add a DNN layer after the BiLSTM with BatchNormalization\n",
        "    model_a.add(Dense(512, activation='relu'))\n",
        "    model_a.add(BatchNormalization())  # Add BatchNormalization layer\n",
        "\n",
        "    model_a.add(Dense(1))\n",
        "    model_a.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
        "\n",
        "    # Train the Arousal model\n",
        "    model_a.fit(X_train, y_a_train, validation_data=(X_val, y_a_val), epochs=25, batch_size=32)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    predictions_a = model_a.predict(X_test)\n",
        "\n",
        "    # Reshape predictions_a to match the shape of y_a_test\n",
        "    predictions_a = predictions_a.reshape(y_a_test.shape)\n",
        "\n",
        "    # Calculate additional evaluation metrics\n",
        "    mse_a.append(mean_squared_error(y_a_test, predictions_a))\n",
        "    mae_a.append(mean_absolute_error(y_a_test, predictions_a))\n",
        "    rmse_a.append(np.sqrt(mean_squared_error(y_a_test, predictions_a)))\n",
        "    r2_a.append(r2_score(y_a_test, predictions_a))\n",
        "\n",
        "    # Convert regression predictions to binary labels\n",
        "    threshold = 0\n",
        "    binary_predictions_a = (predictions_a >= threshold).astype(int)\n",
        "    y_a_test_binary = (y_a_test >= threshold).astype(int)\n",
        "\n",
        "    # Calculate F1-score, accuracy, precision, and recall for binary classification\n",
        "    f1_a.append(f1_score(y_a_test_binary, binary_predictions_a))\n",
        "    accuracy_a.append(accuracy_score(y_a_test_binary, binary_predictions_a))\n",
        "    precision_a.append(precision_score(y_a_test_binary, binary_predictions_a))\n",
        "    recall_a.append(recall_score(y_a_test_binary, binary_predictions_a))\n",
        "\n",
        "# Calculate average performance across all folds\n",
        "average_mse_a = np.mean(mse_a)\n",
        "average_mae_a = np.mean(mae_a)\n",
        "average_rmse_a = np.mean(rmse_a)\n",
        "average_r2_a = np.mean(r2_a)\n",
        "average_f1_a = np.mean(f1_a)\n",
        "average_accuracy_a = np.mean(accuracy_a)\n",
        "average_precision_a = np.mean(precision_a)\n",
        "average_recall_a = np.mean(recall_a)\n",
        "\n",
        "print(f'Average Arousal MSE: {average_mse_a:.4f}')\n",
        "print(f'Average Arousal MAE: {average_mae_a:.4f}')\n",
        "print(f'Average Arousal RMSE: {average_rmse_a:.4f}')\n",
        "print(f'Average Arousal R2 Score: {average_r2_a:.4f}')\n",
        "print(f'Average Arousal F1 Score: {average_f1_a:.4f}')\n",
        "print(f'Average Arousal Accuracy: {average_accuracy_a:.4f}')\n",
        "print(f'Average Arousal Precision: {average_precision_a:.4f}')\n",
        "print(f'Average Arousal Recall: {average_recall_a:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Mv_qWjQftD",
        "outputId": "3976656f-2f90-477c-da1b-e5e3c0f82e87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Epoch 1/25\n",
            "2654/2654 [==============================] - 70s 22ms/step - loss: 0.0580 - val_loss: 0.1067\n",
            "Epoch 2/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0434 - val_loss: 1.3295\n",
            "Epoch 3/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0411 - val_loss: 0.7280\n",
            "Epoch 4/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0396 - val_loss: 2.0996\n",
            "Epoch 5/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0390 - val_loss: 0.3750\n",
            "Epoch 6/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0384 - val_loss: 0.0753\n",
            "Epoch 7/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0383 - val_loss: 0.0588\n",
            "Epoch 8/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0380 - val_loss: 0.1472\n",
            "Epoch 9/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0379 - val_loss: 0.0441\n",
            "Epoch 10/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0378 - val_loss: 7.9151\n",
            "Epoch 11/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0376 - val_loss: 73.4583\n",
            "Epoch 12/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0375 - val_loss: 0.1007\n",
            "Epoch 13/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0375 - val_loss: 10.1700\n",
            "Epoch 14/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0373 - val_loss: 1.2206\n",
            "Epoch 15/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0371 - val_loss: 0.6489\n",
            "Epoch 16/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0372 - val_loss: 0.3614\n",
            "Epoch 17/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0369 - val_loss: 4.4846\n",
            "Epoch 18/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0369 - val_loss: 2.0139\n",
            "Epoch 19/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0367 - val_loss: 0.1432\n",
            "Epoch 20/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0367 - val_loss: 6.5435\n",
            "Epoch 21/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0365 - val_loss: 4.5086\n",
            "Epoch 22/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0364 - val_loss: 5.9751\n",
            "Epoch 23/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0363 - val_loss: 3.7534\n",
            "Epoch 24/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0364 - val_loss: 24.2633\n",
            "Epoch 25/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0363 - val_loss: 4.6657\n",
            "332/332 [==============================] - 3s 7ms/step\n",
            "Epoch 1/25\n",
            "2654/2654 [==============================] - 64s 23ms/step - loss: 0.0535 - val_loss: 0.3743\n",
            "Epoch 2/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0430 - val_loss: 4.0269\n",
            "Epoch 3/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0409 - val_loss: 0.5941\n",
            "Epoch 4/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0395 - val_loss: 0.1123\n",
            "Epoch 5/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0389 - val_loss: 5.9939\n",
            "Epoch 6/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0386 - val_loss: 2.0380\n",
            "Epoch 7/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0381 - val_loss: 2.6468\n",
            "Epoch 8/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0379 - val_loss: 0.8200\n",
            "Epoch 9/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0376 - val_loss: 1.5848\n",
            "Epoch 10/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0374 - val_loss: 0.4793\n",
            "Epoch 11/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0374 - val_loss: 10.7956\n",
            "Epoch 12/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0372 - val_loss: 0.1588\n",
            "Epoch 13/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0369 - val_loss: 3.8814\n",
            "Epoch 14/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0368 - val_loss: 0.8586\n",
            "Epoch 15/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0366 - val_loss: 0.5460\n",
            "Epoch 16/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0366 - val_loss: 15.4416\n",
            "Epoch 17/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0364 - val_loss: 0.1072\n",
            "Epoch 18/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0364 - val_loss: 2.9877\n",
            "Epoch 19/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0362 - val_loss: 0.1194\n",
            "Epoch 20/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0364 - val_loss: 2.7398\n",
            "Epoch 21/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0363 - val_loss: 0.0672\n",
            "Epoch 22/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0362 - val_loss: 2.8980\n",
            "Epoch 23/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0361 - val_loss: 0.0445\n",
            "Epoch 24/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0360 - val_loss: 4.8821\n",
            "Epoch 25/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0360 - val_loss: 0.0632\n",
            "332/332 [==============================] - 3s 7ms/step\n",
            "Epoch 1/25\n",
            "2654/2654 [==============================] - 64s 22ms/step - loss: 0.0567 - val_loss: 0.0553\n",
            "Epoch 2/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0429 - val_loss: 3.6453\n",
            "Epoch 3/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0410 - val_loss: 2.3643\n",
            "Epoch 4/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0396 - val_loss: 0.0457\n",
            "Epoch 5/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0389 - val_loss: 3.2280\n",
            "Epoch 6/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0384 - val_loss: 3.8392\n",
            "Epoch 7/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0382 - val_loss: 1.7494\n",
            "Epoch 8/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0379 - val_loss: 3.7356\n",
            "Epoch 9/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0377 - val_loss: 0.2094\n",
            "Epoch 10/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0376 - val_loss: 0.6637\n",
            "Epoch 11/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0374 - val_loss: 0.1858\n",
            "Epoch 12/25\n",
            "2654/2654 [==============================] - 62s 24ms/step - loss: 0.0373 - val_loss: 0.7495\n",
            "Epoch 13/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0372 - val_loss: 0.1122\n",
            "Epoch 14/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0370 - val_loss: 0.1945\n",
            "Epoch 15/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0368 - val_loss: 0.0432\n",
            "Epoch 16/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0366 - val_loss: 0.6094\n",
            "Epoch 17/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0364 - val_loss: 0.2398\n",
            "Epoch 18/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0364 - val_loss: 0.7990\n",
            "Epoch 19/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0363 - val_loss: 0.3474\n",
            "Epoch 20/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0362 - val_loss: 2.5440\n",
            "Epoch 21/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0361 - val_loss: 2.8942\n",
            "Epoch 22/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0360 - val_loss: 0.4741\n",
            "Epoch 23/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0361 - val_loss: 0.1175\n",
            "Epoch 24/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0359 - val_loss: 0.6305\n",
            "Epoch 25/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0359 - val_loss: 0.1370\n",
            "332/332 [==============================] - 3s 8ms/step\n",
            "Epoch 1/25\n",
            "2654/2654 [==============================] - 62s 22ms/step - loss: 0.0501 - val_loss: 0.2115\n",
            "Epoch 2/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0426 - val_loss: 0.0584\n",
            "Epoch 3/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0407 - val_loss: 0.6808\n",
            "Epoch 4/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0394 - val_loss: 0.0441\n",
            "Epoch 5/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0389 - val_loss: 8.1557\n",
            "Epoch 6/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0385 - val_loss: 1.1202\n",
            "Epoch 7/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0382 - val_loss: 0.0486\n",
            "Epoch 8/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0379 - val_loss: 0.7244\n",
            "Epoch 9/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0378 - val_loss: 0.4787\n",
            "Epoch 10/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0375 - val_loss: 9.4182\n",
            "Epoch 11/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0374 - val_loss: 3.5959\n",
            "Epoch 12/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0370 - val_loss: 0.4879\n",
            "Epoch 13/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0370 - val_loss: 2.6436\n",
            "Epoch 14/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0369 - val_loss: 3.7053\n",
            "Epoch 15/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0368 - val_loss: 0.0431\n",
            "Epoch 16/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0366 - val_loss: 4.9416\n",
            "Epoch 17/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0366 - val_loss: 0.1145\n",
            "Epoch 18/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0366 - val_loss: 0.0769\n",
            "Epoch 19/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0364 - val_loss: 2.3080\n",
            "Epoch 20/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0364 - val_loss: 0.4555\n",
            "Epoch 21/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0364 - val_loss: 0.1243\n",
            "Epoch 22/25\n",
            "2654/2654 [==============================] - 58s 22ms/step - loss: 0.0363 - val_loss: 0.0733\n",
            "Epoch 23/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0363 - val_loss: 1.4223\n",
            "Epoch 24/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0362 - val_loss: 1.3720\n",
            "Epoch 25/25\n",
            "2654/2654 [==============================] - 59s 22ms/step - loss: 0.0363 - val_loss: 0.0541\n",
            "332/332 [==============================] - 3s 8ms/step\n",
            "Epoch 1/25\n",
            "2654/2654 [==============================] - 65s 23ms/step - loss: 0.0570 - val_loss: 0.1503\n",
            "Epoch 2/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0433 - val_loss: 44.1524\n",
            "Epoch 3/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0420 - val_loss: 48.3943\n",
            "Epoch 4/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0405 - val_loss: 2.9775\n",
            "Epoch 5/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0401 - val_loss: 9.7978\n",
            "Epoch 6/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0395 - val_loss: 0.0498\n",
            "Epoch 7/25\n",
            "2654/2654 [==============================] - 62s 24ms/step - loss: 0.0393 - val_loss: 6.0123\n",
            "Epoch 8/25\n",
            "2654/2654 [==============================] - 63s 24ms/step - loss: 0.0388 - val_loss: 16.6213\n",
            "Epoch 9/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0385 - val_loss: 19.3932\n",
            "Epoch 10/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0385 - val_loss: 10.9404\n",
            "Epoch 11/25\n",
            "2654/2654 [==============================] - 60s 22ms/step - loss: 0.0382 - val_loss: 21.3708\n",
            "Epoch 12/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0381 - val_loss: 19.5827\n",
            "Epoch 13/25\n",
            "2654/2654 [==============================] - 60s 23ms/step - loss: 0.0379 - val_loss: 50.4407\n",
            "Epoch 14/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0377 - val_loss: 11.6978\n",
            "Epoch 15/25\n",
            "2654/2654 [==============================] - 64s 24ms/step - loss: 0.0375 - val_loss: 7.0758\n",
            "Epoch 16/25\n",
            "2654/2654 [==============================] - 65s 25ms/step - loss: 0.0374 - val_loss: 3.1409\n",
            "Epoch 17/25\n",
            "2654/2654 [==============================] - 64s 24ms/step - loss: 0.0372 - val_loss: 10.3157\n",
            "Epoch 18/25\n",
            "2654/2654 [==============================] - 66s 25ms/step - loss: 0.0372 - val_loss: 0.3055\n",
            "Epoch 19/25\n",
            "2654/2654 [==============================] - 66s 25ms/step - loss: 0.0370 - val_loss: 74.1432\n",
            "Epoch 20/25\n",
            "2654/2654 [==============================] - 64s 24ms/step - loss: 0.0369 - val_loss: 0.0546\n",
            "Epoch 21/25\n",
            "2654/2654 [==============================] - 67s 25ms/step - loss: 0.0368 - val_loss: 3.2445\n",
            "Epoch 22/25\n",
            "2654/2654 [==============================] - 65s 24ms/step - loss: 0.0367 - val_loss: 1.6268\n",
            "Epoch 23/25\n",
            "2654/2654 [==============================] - 61s 23ms/step - loss: 0.0365 - val_loss: 3.1243\n",
            "Epoch 24/25\n",
            "2654/2654 [==============================] - 63s 24ms/step - loss: 0.0362 - val_loss: 3.9504\n",
            "Epoch 25/25\n",
            "2654/2654 [==============================] - 62s 23ms/step - loss: 0.0361 - val_loss: 3.8419\n",
            "332/332 [==============================] - 3s 9ms/step\n",
            "Average Arousal MSE: 1.7312\n",
            "Average Arousal MAE: 0.9436\n",
            "Average Arousal RMSE: 0.9702\n",
            "Average Arousal R2 Score: -22.8601\n",
            "Average Arousal F1 Score: 0.6675\n",
            "Average Arousal Accuracy: 0.6572\n",
            "Average Arousal Precision: 0.6458\n",
            "Average Arousal Recall: 0.7211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}